{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import preprocessing as preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train_df = pd.read_csv('../../datasets/B. Disease Grading/2. Groundtruths/a. IDRiD_Disease Grading_Training Labels.csv')\n",
    "test_df = pd.read_csv('../../datasets/B. Disease Grading/2. Groundtruths/b. IDRiD_Disease Grading_Testing Labels.csv')'''\n",
    "\n",
    "train_df = pd.read_csv('a. IDRiD_Disease Grading_Training Labels.csv')\n",
    "test_df = pd.read_csv('b. IDRiD_Disease Grading_Testing Labels.csv')\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.head()\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(i):\n",
    "    img = cv2.imread(i)\n",
    "    img = img[0:3000,300:3670]\n",
    "    width = 299\n",
    "    height = 299\n",
    "    dim = (width, height)\n",
    "\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    blurred = cv2.blur(resized, ksize=(15, 15))\n",
    "    diff = resized - blurred\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = train_df.shape[0]\n",
    "x_train = np.empty((N, 299, 299, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(train_df['Image name'])):\n",
    "    #print(image_id)\n",
    "    #print(f'../../datasets/B. Disease Grading/1. Original Images/a. Training Set/{image_id}.jpg')\n",
    "    x_train[i, :, :, :] = process(\n",
    "        f'drive/My Drive/1. Original Images/a. Training Set/{image_id}.jpg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = test_df.shape[0]\n",
    "x_test = np.empty((N, 299, 299, 3), dtype=np.uint8)\n",
    "for i, image_id in enumerate(tqdm(test_df['Image name'])):\n",
    "    x_train[i, :, :, :] = process(\n",
    "        f'drive/My Drive/1. Original Images/b. Testing Set/{image_id}.jpg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (train_df['Retinopathy grade']).values\n",
    "y_test = (test_df['Retinopathy grade']).values\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, \n",
    "    test_size=0.1, \n",
    "    random_state=2020\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "print(y_train.shape)\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 299, 299\n",
    "nb_train_samples = 413\n",
    "nb_validation_samples = 103\n",
    "epochs = 300\n",
    "\n",
    "model = applications.InceptionV3(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"cosine_proximity\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=0, \n",
    "                                   # zoom_range = 0.3, \n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, \n",
    "                                   horizontal_flip = 'true')\n",
    "train_generator = train_datagen.flow(x_train, y_train, shuffle=False, batch_size=batch_size, seed=10)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_generator = train_datagen.flow(x_val, y_val, shuffle=False, batch_size=batch_size, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"inception_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch=x_train.shape[0] / batch_size,\n",
    "epochs=epochs,\n",
    "validation_data = val_generator,\n",
    "callbacks = [checkpoint, early,plot_losses]\n",
    "verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('inception_1.h5')\n",
    "y_test = model.predict(x_test, verbose=2)\n",
    "y_pred = y_test.argmax(axis=1)\n",
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "print(roc_auc_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
